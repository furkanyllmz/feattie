# ğŸ›ï¸ Shopify RAG Product Search & Recommendation System

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-green.svg)](https://fastapi.tiangolo.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Enterprise-grade AI-powered product search and recommendation system using **RAG (Retrieval-Augmented Generation)** with flexible embedding providers and GPT-4 integration.

## âœ¨ Key Features

- ğŸ” **Semantic Search**: Natural language product search in 100+ languages (Turkish, English, etc.)
- ğŸ¤– **AI Assistant**: GPT-4 powered product recommendations with context awareness
- âš¡ **Flexible Embeddings**: Switch between OpenAI or local (sentence-transformers) embeddings
- ğŸš€ **High Performance**: In-memory embedding cache, FastAPI async architecture
- ğŸ’¬ **Embeddable Widget**: One-line JavaScript integration for any website
- ğŸ”§ **Production Ready**: YAML config, Docker support, comprehensive error handling
- ğŸ“Š **Scalable**: Handles 10,000+ products with sub-second response times

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Widget    â”‚â”€â”€â”€â”€â”€â–¶â”‚  FastAPI     â”‚â”€â”€â”€â”€â”€â–¶â”‚  RAG Engine â”‚
â”‚ (Frontend)  â”‚      â”‚   Server     â”‚      â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                      â”‚
                            â–¼                      â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Assistant  â”‚       â”‚  Embeddings â”‚
                     â”‚   (GPT-4)    â”‚       â”‚  (Flexible) â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â–¼                             â–¼
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚   OpenAI    â”‚            â”‚  Sentence-     â”‚
                             â”‚  Embeddings â”‚            â”‚  Transformers  â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
feattie/
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ embeddings/               # Embedding providers
â”‚   â”‚   â”œâ”€â”€ base.py              # Abstract interface
â”‚   â”‚   â”œâ”€â”€ openai_embeddings.py # OpenAI provider
â”‚   â”‚   â””â”€â”€ local_embeddings.py  # Local provider
â”‚   â”œâ”€â”€ api/                     # API module
â”‚   â”‚   â””â”€â”€ server.py            # FastAPI server
â”‚   â”œâ”€â”€ rag_engine.py            # RAG search engine
â”‚   â””â”€â”€ assistant.py             # LLM assistant
â”œâ”€â”€ config/                       # Configuration
â”‚   â”œâ”€â”€ config.yaml              # Main config file
â”‚   â””â”€â”€ __init__.py              # Config loader
â”œâ”€â”€ static/js/                   # Frontend assets
â”‚   â”œâ”€â”€ widget.js                # Chat widget
â”‚   â””â”€â”€ widget-loader.js         # Widget loader
â”œâ”€â”€ out/                         # Data files
â”‚   â”œâ”€â”€ products_rag.jsonl       # RAG-optimized data
â”‚   â””â”€â”€ products_sot.jsonl       # Source of truth
â”œâ”€â”€ run.py                       # Main entry point
â”œâ”€â”€ shop_pull.py                 # Shopify data scraper
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .env.example                 # Environment template
â””â”€â”€ README.md                    # This file
```

---

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone/navigate to repository
cd feattie

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt


# Setup environment
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY (if using OpenAI)
```

### 2. Configure

Edit `config/config.yaml`:

```yaml
# Choose embedding provider
embedding:
  provider: "openai"  # or "local"

  openai:
    model: "text-embedding-3-large"

  local:
    model: "intfloat/multilingual-e5-large"
    device: "cpu"  # or "cuda" for GPU
```

### 3. Fetch Products

```bash
python shop_pull.py --base-url https://your-shopify-store.com --outdir ./out
```

### 4. Start Server

```bash
python run.py
```

Server starts at: **http://localhost:8000**

ğŸ‰ **Done!** Embeddings are created on first startup (~30-60 seconds) and cached in memory.

---

## ğŸ“– Usage

### REST API

#### Search Products

```bash
curl -X POST "http://localhost:8000/search" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "siyah hoodie playstation",
    "top_k": 3,
    "deduplicate": true
  }'
```

**Response:**
```json
{
  "query": "siyah hoodie playstation",
  "results": [
    {
      "product_id": 7718603915343,
      "title": "HOODIE 501 â€” Black / XS",
      "vendor": "LES BENJAMINS",
      "price": 4499.0,
      "similarity": 0.625
    }
  ],
  "count": 1
}
```

#### Ask AI Assistant

```bash
curl -X POST "http://localhost:8000/ask" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "300 TL altÄ±nda sweatshirt Ã¶ner",
    "top_k": 3
  }'
```

#### Get Product IDs

```bash
curl -X POST "http://localhost:8000/product-ids" \
  -H "Content-Type: application/json" \
  -d '{"query": "mavi pantolon", "top_k": 5}'
```

#### API Documentation

Interactive docs: **http://localhost:8000/docs**

---

### Python SDK

```python
from src.rag_engine import ProductRAG
from src.assistant import ProductAssistant

# Initialize with OpenAI embeddings
rag = ProductRAG(
    jsonl_path="./out/products_rag.jsonl",
    embedding_provider="openai",
    embedding_model="text-embedding-3-large"
)

# Or use local embeddings (free!)
rag = ProductRAG(
    jsonl_path="./out/products_rag.jsonl",
    embedding_provider="local",
    embedding_model="intfloat/multilingual-e5-large",
    device="cpu"
)

# Create embeddings
rag.create_embeddings()

# Search
results = rag.search("siyah hoodie playstation", top_k=3)
for r in results:
    print(f"{r['product']['title']} - {r['similarity']:.3f}")

# Get IDs
product_ids = rag.get_product_ids("mavi pantolon", top_k=5)

# AI Assistant
assistant = ProductAssistant(rag, model="gpt-4o-mini")
response = assistant.ask("500 TL altÄ±nda Ã¼rÃ¼n Ã¶ner")
print(response)
```

---

### Chat Widget Integration

#### One-Line Integration

Add to your website's `<head>` or `<body>`:

```html
<script src="http://localhost:8000/static/js/widget-loader.js"></script>
```

#### Customization

```html
<script>
  window.SHOPIFY_RAG_API_URL = 'https://your-api-server.com';
  window.SHOPIFY_RAG_COLOR = '#FF6B6B';
  window.SHOPIFY_RAG_TITLE = 'Product Assistant';
  window.SHOPIFY_RAG_POSITION = 'bottom-right';
</script>
<script src="https://your-api-server.com/static/js/widget-loader.js"></script>
```

#### Shopify Integration

1. **Online Store** â†’ **Themes** â†’ **Actions** â†’ **Edit code**
2. Open `theme.liquid`
3. Add before `</head>`:
   ```liquid
   <script src="{{ 'https://your-api-server.com/static/js/widget-loader.js' }}"></script>
   ```
4. Save and publish

---

## âš™ï¸ Configuration

### Embedding Providers

#### OpenAI (Best Quality, Paid)

```yaml
embedding:
  provider: "openai"
  openai:
    model: "text-embedding-3-large"  # Best quality
    # model: "text-embedding-3-small"  # Cheaper alternative
    batch_size: 100
```

**Pros:**
- âœ… Best quality for multilingual search
- âœ… No GPU required
- âœ… Fast API responses

**Cons:**
- âŒ Costs ~$0.52 for initial embedding (12k products)
- âŒ ~$0.0001 per query

#### Local (Free, Private)

```yaml
embedding:
  provider: "local"
  local:
    model: "intfloat/multilingual-e5-large"  # Best quality
    # model: "paraphrase-multilingual-mpnet-base-v2"  # Alternative
    batch_size: 32
    device: "cpu"  # or "cuda"
```

**Pros:**
- âœ… **$0 cost** - completely free!
- âœ… Privacy - data stays local
- âœ… Offline capability

**Cons:**
- âŒ Requires 8GB+ RAM
- âŒ Slower without GPU
- âŒ First-time model download (~2GB)

### Recommended Models

| Provider | Model | Quality | Speed | Cost | Best For |
|----------|-------|---------|-------|------|----------|
| OpenAI | text-embedding-3-large | â­â­â­â­â­ | âš¡âš¡âš¡âš¡ | $$ | Production |
| OpenAI | text-embedding-3-small | â­â­â­â­ | âš¡âš¡âš¡âš¡âš¡ | $ | Budget prod |
| Local | intfloat/multilingual-e5-large | â­â­â­â­â­ | âš¡âš¡âš¡ | Free | Development |
| Local | paraphrase-multilingual-mpnet-base-v2 | â­â­â­â­ | âš¡âš¡âš¡âš¡ | Free | Development |

---

## ğŸ’° Cost Estimation

### OpenAI Embeddings

| Operation | Cost (12k products) |
|-----------|---------------------|
| Initial embedding creation | ~$0.52 |
| Per query embedding | ~$0.0001 |
| GPT-4o-mini response | ~$0.001-0.003 |

**Monthly cost (1000 queries):** ~$3-5

### Local Embeddings

| Operation | Cost |
|-----------|------|
| Everything | **$0** (Free!) |

**Hardware requirements:** 8GB RAM minimum, GPU recommended for >10k products

### ğŸ’¡ Recommended: Local Embedding + OpenAI LLM

**Best of both worlds:**
- Embedding: Local (free)
- LLM responses: OpenAI ($0.002/query)
- **Total: ~$2/month for 1000 queries**

---

## ğŸ› Troubleshooting

### "No module named 'uvicorn'"

```bash
# Make sure virtual environment is activated
source venv/bin/activate
pip install -r requirements.txt
```

### "No module named 'sentence_transformers'"

```bash
pip install -r requirements-local.txt
```

### Embeddings taking too long

- Use `text-embedding-3-small` (5x faster)
- Reduce batch size in config
- Use GPU for local embeddings

### Out of memory

- Reduce number of products
- Use smaller embedding model
- Increase server RAM

### Widget not showing

- Check browser console for errors
- Verify API URL is correct
- Check CORS settings in `config/config.yaml`

### Port 8000 already in use

```yaml
# config/config.yaml
api:
  port: 8001
```

---

## ğŸ³ Docker Deployment

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY . .

# Expose port
EXPOSE 8000

# Run server
CMD ["python", "run.py"]
```

```bash
# Build
docker build -t shopify-rag .

# Run
docker run -p 8000:8000 \
  -e OPENAI_API_KEY=your-key \
  -v $(pwd)/out:/app/out \
  shopify-rag
```

---

## ğŸ“Š Performance

| Metric | Value |
|--------|-------|
| Products indexed | 12,944 |
| Search latency | <100ms |
| Embedding dimension | 3072 (OpenAI large) |
| Memory usage | ~2GB (with embeddings) |
| Throughput | 100+ req/sec |

---

## ğŸ”’ Security

- âœ… API keys stored in `.env` (never commit!)
- âœ… CORS configurable per environment
- âœ… Input validation on all endpoints
- âš ï¸ Rate limiting recommended for production

---

## ğŸ› ï¸ Development

### Local Development Setup

```bash
# Development mode (with auto-reload)
# Edit config/config.yaml:
api:
  reload: true

python run.py
```

### Testing

```bash
# Install test dependencies
pip install pytest httpx

# Run tests
pytest tests/

# Test API manually
python -c "
import requests
resp = requests.get('http://localhost:8000/')
print(resp.json())
"
```

---

## ğŸ“š Advanced Usage

### Custom Embedding Provider

Implement `EmbeddingProvider` interface:

```python
from src.embeddings.base import EmbeddingProvider

class MyCustomEmbeddings(EmbeddingProvider):
    def embed_texts(self, texts, batch_size):
        # Your implementation
        pass

    def embed_query(self, query):
        # Your implementation
        pass
```

### Batch Processing

```python
# Process multiple queries
queries = ["query1", "query2", "query3"]
for q in queries:
    results = rag.search(q, top_k=5)
    print(f"{q}: {len(results)} results")
```

---

## ğŸ“„ License

MIT License - see LICENSE file

---

## ğŸ™ Acknowledgments

- Built with [FastAPI](https://fastapi.tiangolo.com/)
- Embeddings by [OpenAI](https://openai.com/) and [Sentence-Transformers](https://www.sbert.net/)
- Inspired by modern RAG architectures

---

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/your-org/shopify-rag/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-org/shopify-rag/discussions)
- **Documentation**: This README
- **API Docs**: http://localhost:8000/docs

---

**Made with â¤ï¸ by Feattie**

*Last updated: 2025*
